#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Author: Daniel Rode


"""Create first order derivative products.

Catalog collection, remove noise/artifacts, generate 1OD gridded metric
rasters, and organize products.
"""


# -----------------------------------------------------------------------------
# -----------------------------------------------------------------------------
# Import libraries
# -----------------------------------------------------------------------------
# -----------------------------------------------------------------------------

# Import standard libraries
import os
import sys
import random
import zipfile
import subprocess as sp
from pathlib import Path

# Import in-house libraries
from vogeler.stdlib import print2
from vogeler.stdlib import init_logger
from vogeler.stdlib import sha1
from vogeler.stdlib import get_path_stem
from vogeler.stdlib import apply_naming_scheme
from vogeler.extlib import catshp
from vogeler.extlib import tif_m2ft
from vogeler.extlib import update_crs_metadata
from vogeler.extlib import vpc2df
from vogeler.sp import gdal_build_vrt
from vogeler.sp import build_vpc
from vogeler.sp import clip_rast
from vogeler.sp import gdaladdo
from vogeler.sp import parallel
from vogeler.sp import find

# Import external libraries
import pyogrio
import xmltodict
from geopandas import GeoDataFrame


# -----------------------------------------------------------------------------
# -----------------------------------------------------------------------------
# Constants
# -----------------------------------------------------------------------------
# -----------------------------------------------------------------------------

MAX_WORKERS = os.cpu_count()  # Number of CPU cores available on machine
HOTSPOT_BUFF = 50  # Amount to buffer pixels (in meters) for hotspot fix bounds
TILE_LENGTH = 5 * 2**9  # Max virtual tile side length
TILE_MAX_POINTS = 2**28  # Max number of points per virtual tile

# Seed passed to random number generator
RF_SEED = 28  # "BH" = 28 in A1Z26 cipher

# Tile edge buffer when generating gridded metrics to avoid
# edge-effects/artifacts
TILE_BUFFER = 40

# EPSG code for UTM Zone 13N, without vertical (Z) component
FLAT_UTM13N_EPSG = 6342

# File paths to Black Hills lidar tile polygons, point clouds, and DTM rasters,
# for Block 1 and Block 2
VENDOR_SHP_PATHS = (
    Path(
        "/import/vendor/"
        "USGS_SD_BlackHills_Preliminary_Delivery_Block1_09272023/Layout/"
        "SD_BlackHills_D23_MTI_Block1.shp"
    ),
    Path(
        "/import/vendor/"
        "USGS_SD_BlackHills_Preliminary_Delivery_Block2/Layout/"
        "SD_BlackHills_D23_MTI_Block2.shp"
    ),
)
LAS_FILE_EXTENTIONS = (
    "*.laz",
)
VENDOR_LAS_DIRS = (
    Path(
        "/import/vendor/"
        "USGS_SD_BlackHills_Preliminary_Delivery_Block1_09272023/pointcloud/"
    ),
    Path(
        "/import/vendor/"
        "USGS_SD_BlackHills_Preliminary_Delivery_Block2/pointcloud/"
    ),
)
VENDOR_DTM_DIRS = (
    Path(
        "/import/vendor/"
        "USGS_SD_BlackHills_Preliminary_Delivery_Block1_09272023/DEM/"
    ),
    Path(
        "/import/vendor/"
        "USGS_SD_BlackHills_Preliminary_Delivery_Block2/DEM/"
    ),
)

# File paths to NDVI rasters
NDVI_TIF_PATHS = (
    Path(
        '/import/rstor/ancillary_data/naip_ndvi/rev3_110124/'
        'ndvi_block1_06m_110124_mosaic.tif'
    ),
    Path(
        '/import/rstor/ancillary_data/naip_ndvi/rev3_110124/'
        'ndvi_block2_06m_110124_mosaic.tif'
    ),
)

# File paths to polygons delineating communication towers
TOWER_SHP_PATHS = (
    Path(
        "/import/rstor/qaqc/object_digitization/block_1/manmade_towers/"
        "rev1_111824/b1_manmade_towers.gpkg"
    ),
    Path(
        "/import/rstor/qaqc/object_digitization/block_2/manmade_towers/"
        "block2_manmade_towers_BH_intersect.gpkg"
    ),
)

# File paths to polygons delineating powerlines
POWERLINE_SHP_PATHS = (
    Path(
        "/import/rstor/qaqc/object_digitization/block_1/"
        "powerlines_and_power_towers/rev1_111824/b1_powerlines.gpkg"
    ),
    Path(
        "/import/rstor/qaqc/Kelly_request_2024-01-13/polygons/"
        "BH_b2_powerlines_revised_021025.gpkg"
    ),
)

# File path to polygons delineating buildings
BUILDINGS_SHP_PATHS = (
    Path(
        "/import/rstor/qaqc/object_digitization/buildings/"
        "bhnf_buildings.gpkg"
    ),
)

# File path to polygons delineating Black Hills National Forest lands boundary
FS_BOUNDS = Path("/import/rstor/ancillary_data/bh_fs_shp/bh_fs.gpkg")


# -----------------------------------------------------------------------------
# -----------------------------------------------------------------------------
# Functions
# -----------------------------------------------------------------------------
# -----------------------------------------------------------------------------

def irange(start: int, end: int) -> range:
    """Inclusive range function."""

    return range(start, end + 1)


def patch_ctg_asset_list(
    raw_asset_paths: list[Path],
    patched_asset_paths: list[Path],
) -> list[Path]:
    """Update catalog assets list with patched assets.

    Given a list of collection assets (LAS/LAZ files, GeoTIFFs, etc...) if any
    filenames (minus file extension) match those in the given list of
    patched asset paths (regardless of upper/lowercase), drop that "raw"
    asset path from the list. Return remaining file paths from the original
    list in addition to all patched asset tile paths as one list.
    """

    patched_asset_paths = list(patched_asset_paths)
    asset_paths = []
    lower_patched_names = [
        get_path_stem(i).lower()
        for i in patched_asset_paths
    ]
    for p in raw_asset_paths:
        if get_path_stem(p).lower() not in lower_patched_names:
            asset_paths += [p]

    return asset_paths + patched_asset_paths


def iglob(dir_path: Path, pat: str) -> list[Path]:
    """Case insensitive Path.glob().

    Return list of files that match given glob pattern, regardless of pattern
    case, in the given directory.
    """

    return list(dir_path.glob(pat, case_sensitive=False))


def vrt_assets_relative(vrt_path: Path) -> bool:
    """Verify VRT assets are relative.

    Take a given VRT (virtual raster/mosaic) and check whether its asset paths
    are relative to the given VRT.
    """

    # Load XML generated by GDAL
    with vrt_path.open('r') as f:
        vrt = xmltodict.parse(f.read())

    # Update file paths so they are relative
    for s in ('SimpleSource', 'ComplexSource'):
        if s not in vrt['VRTDataset']['VRTRasterBand']:
            continue
        for i in vrt['VRTDataset']['VRTRasterBand'][s]:
            if i['SourceFilename']['@relativeToVRT'] != '1':
                return False

    return True


# -----------------------------------------------------------------------------
# -----------------------------------------------------------------------------
# Main
# -----------------------------------------------------------------------------
# -----------------------------------------------------------------------------

# Parse command line arguments
try:
    DST = Path(sys.argv[1])
except IndexError:
    print2("Specify destination directory for products")
    sys.exit(1)

# Ensure product output directory exists
DST.mkdir(exist_ok=True, parents=True)

# Setup logging
dep_counter = 0  # Dependency counter (for what number prefix to give product)
log = init_logger(DST / f"{dep_counter:02d}_workflow.log")

# Create a directory with links to original lidar files (so all tiles are in)
# one place
dep_counter += 1
las_link_dir = DST / f"{dep_counter:02d}_src_las_dir"
if not las_link_dir.exists():
    log.info("Linking to source lidar tiles...")
    las_link_dir.mkdir(exist_ok=True)

    las_paths_list = [
        tile_path
        for src_dir in VENDOR_LAS_DIRS
        for file_ext in LAS_FILE_EXTENTIONS
        for tile_path in iglob(src_dir, file_ext)
    ]

    for src_tile_path in las_paths_list:
        dst_path = las_link_dir / src_tile_path.name

        # Ensure no tiles have share file names
        if dst_path.exists():
            raise Exception(f"Path exists (will not overwrite): {dst_path}")

        log.info("%s  -->  %s", dst_path, src_tile_path)
        os.symlink(src_tile_path, dst_path)

# Create a directory with links to original DTM files (so all tiles are in)
# one place
dtm_link_dir = DST / f"{dep_counter:02d}_src_dtm_dir"
if not dtm_link_dir.exists():
    log.info("Linking to source DTM tiles...")
    dtm_link_dir.mkdir(exist_ok=True)

    tif_paths_list = [
        tile_path
        for src_dir in VENDOR_DTM_DIRS
        for tile_path in iglob(src_dir, "*.tif")
    ]

    for src_tile_path in tif_paths_list:
        dst_path = dtm_link_dir / src_tile_path.name

        # Ensure no tiles have share file names
        if dst_path.exists():
            raise Exception(f"Path exists (will not overwrite): {dst_path}")

        log.info("%s  -->  %s", dst_path, src_tile_path)
        os.symlink(src_tile_path, dst_path)

# Catalog vendor/source point cloud tiles
dep_counter += 1
raw_ctg_path = DST / f"{dep_counter:02d}_raw_ctg.vpc"
if not raw_ctg_path.exists():
    log.info("Catalogging source lidar tiles...")
    tile_list = [
        tile_path
        for file_ext in LAS_FILE_EXTENTIONS
        for tile_path in iglob(las_link_dir, file_ext)
    ]
    build_vpc(tile_list, raw_ctg_path)

# Stitch (mosaic) tiles of rasters and shapefiles used for locating artifacts
# (rocks, infrastructure, etc...) in point clouds
ndvi_vrt_path = DST / f"{dep_counter:02d}_ndvi.vrt"
if not ndvi_vrt_path.exists():
    log.info("Stitching NDVI rasters...")
    gdal_build_vrt(NDVI_TIF_PATHS, ndvi_vrt_path)

towers_shp_path = DST / f"{dep_counter:02d}_towers.fgb"
if not towers_shp_path.exists():
    log.info("Stitching communication tower shapefiles...")
    catshp(TOWER_SHP_PATHS, towers_shp_path)

pwr_shp_path = DST / f"{dep_counter:02d}_powerlines.fgb"
if not pwr_shp_path.exists():
    log.info("Stitching powerline shapefiles...")
    catshp(POWERLINE_SHP_PATHS, pwr_shp_path)

# Stitch (mosaic) vendor DTM
vendor_dtm_mosaic_path = DST / f"{dep_counter:02d}_vendor_dtm.vrt"
if not vendor_dtm_mosaic_path.exists():
    log.info("Stitching vendor DTM rasters...")
    gdal_build_vrt(
        [
            tile_path
            for src_dir in VENDOR_DTM_DIRS
            for tile_path in iglob(src_dir, "*.tif")
        ],
        vendor_dtm_mosaic_path,
    )

# Clean (height normalize, etc...) vendor point cloud tiles and spatially index
# points (convert to COPC)
dep_counter += 1
clean_las_dir = DST / f"{dep_counter:02d}_cleaned_point_clouds/"
if not clean_las_dir.exists():
    log.info("Cleaning vendor point clouds...")
    clean_las_dir.mkdir(exist_ok=True)
    las_paths_list = sorted([
        tile_path
        for src_dir in VENDOR_LAS_DIRS
        for tile_path in iglob(src_dir, "*.laz")
    ])
    dtm_paths_list = sorted([
        tile_path
        for src_dir in VENDOR_DTM_DIRS
        for tile_path in iglob(src_dir, "*.tif")
    ])
    assert len(las_paths_list) == len(dtm_paths_list)
    jobs = []
    for las, dtm in zip(las_paths_list, dtm_paths_list):
        assert get_path_stem(las).lower() == get_path_stem(dtm).lower()
        dst = f"{clean_las_dir}/{get_path_stem(las)}.copc.laz"
        jobs += [[str(las), str(dtm), dst]]
    parallel(
        jobs,
        'clean-las',
        joblog=str(clean_las_dir) + '_jobs.log',
        # Warning: Too many concurrent thread will cause OOM error
        max_procs=MAX_WORKERS,
    )

# Catalog cleaned COPC point cloud tiles
dep_counter += 1
cleaned_ctg_path = DST / f"{dep_counter:02d}_cleaned_ctg.vpc"
if not cleaned_ctg_path.exists():
    log.info("Catalogging point clouds tiles...")
    clean_las_list = clean_las_dir.glob('*.copc.laz')
    build_vpc(clean_las_list, cleaned_ctg_path)

# Generate cursory grid-metrics for identifying hotspots
cursory_tile_dir = DST / f"{dep_counter:02d}_cursory_grid_metrics_tiles"
if not cursory_tile_dir.exists():
    log.info("Generating grid-metrics for identifying hotspots...")
    cursory_tile_dir.mkdir(exist_ok=True)
    jobs = [
        [str(las), str(cursory_tile_dir / las.name)]
        for las in clean_las_dir.glob("*")
    ]
    parallel(
        jobs,
        'cursory-gridmetrics',
        joblog=str(cursory_tile_dir) + '_jobs.log',
        # Warning: Too many concurrent threads will cause OpenBLAS to glitch
        max_procs=MAX_WORKERS,
    )

# Virtually stitch (mosaic) cursory grid metrics rasters
dep_counter += 1
cursory_mosaic_dir = DST / f"{dep_counter:02d}_cursory_grid_metrics_mosaics"
if not cursory_mosaic_dir.exists():
    log.info("Stitching cursory grid metric tiles...")
    cursory_mosaic_dir.mkdir(exist_ok=True)

    def find_tiles(x):
        return find(
            f'^{x}$', [cursory_tile_dir],
            ignore_case=True, result_type=['file'],
        )
    gdal_build_vrt(
        find_tiles('i_first_stdev.tif'),
        cursory_mosaic_dir / "cursory_i_first_stdev.vrt",
    )
    gdal_build_vrt(
        find_tiles('i_first_mean.tif'),
        cursory_mosaic_dir / "cursory_i_first_mean.vrt",
    )
    gdal_build_vrt(
        find_tiles('x_all_count.tif'),
        cursory_mosaic_dir / "cursory_x_all_count.vrt",
    )
    gdal_build_vrt(
        find_tiles('i_first_count.tif'),
        cursory_mosaic_dir / "cursory_i_first_count.vrt",
    )
    gdal_build_vrt(
        find_tiles('x_first_hp_count.tif'),
        cursory_mosaic_dir / "cursory_x_first_hp_count.vrt",
    )

# Find hotspots (locations where rock artifacts are likely to be)
dep_counter += 1
hotspots_shp_path = DST / f"{dep_counter:02d}_hotspots.fgb"
if not hotspots_shp_path.exists():
    log.info("Locating rock hotspots...")
    cmd = [
        'find-hotspots',
        str(cursory_mosaic_dir / "cursory_i_first_stdev.vrt"),
        str(cursory_mosaic_dir / "cursory_i_first_mean.vrt"),
        str(cursory_mosaic_dir / "cursory_x_all_count.vrt"),
        str(cursory_mosaic_dir / "cursory_i_first_count.vrt"),
        str(cursory_mosaic_dir / "cursory_x_first_hp_count.vrt"),
        str(hotspots_shp_path),
    ]
    sp.run(cmd, check=True)

# Find and outline rock artifacts
dep_counter += 1
hotspot_finding_workdir = DST / f"{dep_counter:02d}_hotspot_segments"
if not hotspot_finding_workdir.exists():
    log.info("Finding rocks...")
    with zipfile.ZipFile('/vogeler/data.zip', 'r') as zip_ref:
        zip_ref.extractall('/vogeler/data')
    cmd = [
        'find-rocks',
        str(cleaned_ctg_path),
        str(ndvi_vrt_path),
        str(hotspots_shp_path), str(HOTSPOT_BUFF),
        "/vogeler/data/rocks-training.csv",
        str(hotspot_finding_workdir),
    ]
    sp.run(cmd, check=True)

# Patch COPC point cloud tiles to remove/flag artifacts
dep_counter += 1
patchd_las_dir = DST / f"{dep_counter:02d}_patched_point_clouds/"
if not patchd_las_dir.exists():
    log.info("Patching LAS files...")
    cmd = [
        'patch-las',
        '--max-workers', '4',
        str(VENDOR_BLOCK1_LAS_DIR),
        str(VENDOR_BLOCK1_SHP_PATH),
        str(vendor_dtm_mosaic_path),
        str(hotspot_finding_workdir / "rocks.gpkg"),
        str(pwr_shp_path),
        str(towers_shp_path),
        str(BUILDINGS_SHP_PATH),
        str(patchd_las_dir),
    ]
    sp.run(cmd, check=True)
    cmd = [
        'patch-las',
        '--max-workers', '4',
        str(VENDOR_BLOCK2_LAS_DIR),
        str(VENDOR_BLOCK2_SHP_PATH),
        str(vendor_dtm_mosaic_path),
        str(hotspot_finding_workdir / "rocks.gpkg"),
        str(pwr_shp_path),
        str(towers_shp_path),
        str(BUILDINGS_SHP_PATH),
        str(patchd_las_dir),
    ]
    sp.run(cmd, check=True)

# Generate new point cloud catalog that uses the new patched tiles, where
# available
dep_counter += 1
patched_vendor_vpc_path = DST / f"{dep_counter:02d}_patched_vendor_ctg.vpc"
if not patched_vendor_vpc_path.exists():
    log.info("Catalogging unnormalized patched point clouds...")
    patched_las_ctg_asset_paths = patch_ctg_asset_list(
        raw_asset_paths=[
            *iglob(VENDOR_BLOCK1_LAS_DIR, "*.laz"),
            *iglob(VENDOR_BLOCK2_LAS_DIR, "*.laz"),
        ],
        patched_asset_paths=iglob(patchd_las_dir, "*.laz"),
    )
    build_vpc(patched_las_ctg_asset_paths, patched_vendor_vpc_path)

# Patch DTM rasters (to remove rock artifacts)
dep_counter += 1
patched_dtm_tiles_dir = DST / f"{dep_counter:02d}_patched_dtm/"
if not patched_dtm_tiles_dir.exists():
    log.info("Patching DTM rasters...")
    blocks = (
        (VENDOR_BLOCK1_DTM_DIR, VENDOR_BLOCK1_SHP_PATH),
        (VENDOR_BLOCK2_DTM_DIR, VENDOR_BLOCK2_SHP_PATH),
    )
    for dtm_dir, shp_path in blocks:
        cmd = [
            'patch-dtm',
            str(dtm_dir),
            str(shp_path),
            str(patched_vendor_vpc_path),
            str(hotspot_finding_workdir / "rocks.gpkg"),
            str(patched_dtm_tiles_dir),
        ]
        sp.run(cmd, check=True)

# Generate new virtual DTM mosaic (VRT) that uses the new patched tiles, where
# available
dep_counter += 1
patched_dtm_vrt_path = DST / f"{dep_counter:02d}_patched_dtm.vrt"
if not patched_dtm_vrt_path.exists():
    log.info("Stitching corrected DTM tiles...")
    patched_dtm_asset_paths = patch_ctg_asset_list(
        raw_asset_paths=[
            *iglob(VENDOR_BLOCK1_DTM_DIR, "*.tif"),
            *iglob(VENDOR_BLOCK2_DTM_DIR, "*.tif"),
        ],
        patched_asset_paths=iglob(
            patched_dtm_tiles_dir / "patched_tiles/", "*.tif"
        ),
    )
    gdal_build_vrt(patched_dtm_asset_paths, patched_dtm_vrt_path)

# Clean (height normalize, etc...) patched point clouds
clean_patched_las_dir = DST / f"{dep_counter:02d}_cleaned_patched_point_clouds"
if not clean_patched_las_dir.exists():
    log.info("Cleaning patched point clouds...")
    clean_patched_las_dir.mkdir(exist_ok=True)
    jobs = []
    for las in iglob(patchd_las_dir, "*.laz"):
        job_id = las.stem
        for d in (
            patched_dtm_tiles_dir / "patched_tiles/",
            VENDOR_BLOCK1_DTM_DIR,
            VENDOR_BLOCK2_DTM_DIR,
        ):
            matches = iglob(d, f"{job_id}.tif")
            if len(matches) == 1:
                dtm = matches[0]
                break
            elif len(matches) == 0:
                continue
            else:
                raise Exception(
                    "More than one DTM tile match for given LAS tile: "
                    f"{job_id}"
                )
        else:
            raise Exception(
                f"No DTM tile match for given LAS tile: {job_id}"
            )
        dst = f"{clean_patched_las_dir}/{job_id}.copc.laz"
        jobs += [[str(las), str(dtm), dst]]
    parallel(
        jobs,
        'clean-las',
        joblog=str(clean_patched_las_dir) + '_jobs.log',
        # Warning: Too many concurrent thread will cause OOM error
        max_procs=MAX_WORKERS,
    )

# Stitch (mosaic) DTM and clip it to Forest Service boundaries
dep_counter += 1
patched_clipped_dtm_path = (
    DST / f"{dep_counter:02d}_patched_dtm_clipped_fs.tif"
)
if not patched_clipped_dtm_path.exists():
    log.info("Clipping patched DTM to forest bounds...")
    clip_rast(
        src_tif=patched_dtm_vrt_path,
        dst_tif=patched_clipped_dtm_path,
        bounds=pyogrio.read_dataframe(FS_BOUNDS),
    )

# Generate new cleaned point cloud catalog that uses the new patched tiles,
# where available
clean_patched_vpc_path = (
    DST / f"{dep_counter:02d}_cleaned_patched_point_clouds_ctg.vpc"
)
if not clean_patched_vpc_path.exists():
    log.info("Catalogging cleaned and patched point clouds...")
    cleaned_patched_las_ctg_asset_paths = patch_ctg_asset_list(
        raw_asset_paths=iglob(clean_las_dir, "*.copc.laz"),
        patched_asset_paths=iglob(
            clean_patched_las_dir, "*.copc.laz"
        ),
    )
    build_vpc(
        cleaned_patched_las_ctg_asset_paths,
        clean_patched_vpc_path,
    )

# Generate grid-metric/CHM product rasters
dep_counter += 1
gridmet_tiles_dir = DST / f"{dep_counter:02d}_gridmetrics_chms"
if not gridmet_tiles_dir.exists():
    log.info("Generating grid metrics and CHMs...")
    jobs = []
    tiles = list(vpc2df(clean_patched_vpc_path)['geometry'])
    # Shuffle tiles so that clusters of large and small tiles will be less likely
    # to be processed at the same time (more evenly distributing computational
    # load over time)
    random.seed(RF_SEED)  # Set RNG seed
    random.shuffle(tiles)
    for geom in tiles:
        tile_id = sha1(geom.wkt)
        dst_dir = gridmet_tiles_dir / tile_id

        if (dst_dir / 'DONE').exists():
            print("Exists (skipping):", dst_dir)
            continue

        jobs += [(
            '--max-threads', str(MAX_WORKERS),
            '--bounds-wkt', geom.wkt,
            str(clean_patched_vpc_path),
            str(dst_dir),
            str(TILE_BUFFER),
        )]

    parallel(
        jobs,
        'gridmetrics+chms',
        joblog=str(gridmet_tiles_dir) + '_jobs.log',
        max_procs=MAX_WORKERS,
        # Minimum memory free when starting another jobs
        memfree="80%",
        # Suspend jobs when there is less memory available
        memsuspend="90%",
    )

# Unstack and stitch (mosaic) grid-metric raster tiles
dep_counter += 1
gridmet_mosaics_dir = DST / f"{dep_counter:02d}_gridmetrics_mosaics"
if not gridmet_mosaics_dir.exists():
    log.info("Unstacking and stitching grid metrics tiles...")
    cmd = (
        'unstack+mosaic-rasts',
        str(gridmet_tiles_dir),
        str(gridmet_mosaics_dir),
    )
    sp.run(cmd, check=True)

# Virtually stitch (mosaic) CHMs raster tiles
chm1m_vrt_path = DST / f"{dep_counter:02d}_chm1m.vrt"
if not chm1m_vrt_path.exists():
    log.info("Virtually stitching 1m CHM...")
    chm1m_tile_list = gridmet_tiles_dir.glob('**/chm1m.tif')
    gdal_build_vrt(chm1m_tile_list, chm1m_vrt_path)
    if not vrt_assets_relative(chm1m_vrt_path):
        # Warn if virtual raster asset paths are not relative to virtual raster
        log.warning(f"Asset paths are not relative: {chm1m_vrt_path}")

chm05m_vrt_path = DST / f"{dep_counter:02d}_chm05m.vrt"
if not chm05m_vrt_path.exists():
    log.info("Virtually stitching 05m CHM...")
    chm05m_tile_list = gridmet_tiles_dir.glob('**/chm05m.tif')
    gdal_build_vrt(chm05m_tile_list, chm05m_vrt_path)
    if not vrt_assets_relative(chm05m_vrt_path):
        # Warn if virtual raster asset paths are not relative to virtual raster
        log.warning(f"Asset paths are not relative: {chm05m_vrt_path}")

# Convert CHMs from meters to feet
chm1m_ft_tiles_dir = DST / f"{dep_counter:02d}_chm1m_ft_tiles"
chm05m_ft_tiles_dir = DST / f"{dep_counter:02d}_chm05m_ft_tiles"
for dst_tile_dir, res in (
    (chm1m_ft_tiles_dir, "1"),
    (chm05m_ft_tiles_dir, "05"),
):
    if not dst_tile_dir.exists():
        log.info("Converting CHM %sm tiles to feet...", res)
        dst_tile_dir.mkdir(exist_ok=True)
        src_tifs = gridmet_tiles_dir.glob(f'**/chm{res}m.tif')
        for i, p in enumerate(src_tifs):
            dst = Path(dst_tile_dir / f"{i}.tif")
            log.info("%s  -->  %s.tif", p, i)
            tif_m2ft(p, dst)

# Virtually stitch (mosaic) feet version of CHMs
dep_counter += 1
chm1m_ft_vrt_path = DST / f"{dep_counter:02d}_chm1m_ft.vrt"
chm05m_ft_vrt_path = DST / f"{dep_counter:02d}_chm05m_ft.vrt"
for dst_vrt_path, tile_dir, res in (
    (chm1m_ft_vrt_path, chm1m_ft_tiles_dir, "1"),
    (chm05m_ft_vrt_path, chm05m_ft_tiles_dir, "05"),
):
    if not dst_vrt_path.exists():
        log.info("Virtually stitching %sm CHM...", res)
        tile_list = tile_dir.glob('*.tif')
        gdal_build_vrt(tile_list, dst_vrt_path)
        if not vrt_assets_relative(dst_vrt_path):
            # Warn if VRT asset paths are not relative to virtual raster
            log.warning(f"Asset paths are not relative: {dst_vrt_path}")

# Clip grid-metric products to Forest Service boundary and set NA
# values within study area to 0
clipped_gridmetrics_dir = (
    DST / f"{dep_counter:02d}_gridmetrics_mosaics_fs_clipped"
)
if not clipped_gridmetrics_dir.exists():
    log.info("Clipping products to Forest Service boundaries...")
    tif_list = gridmet_mosaics_dir.glob("*.tif")
    clipped_gridmetrics_dir.mkdir(exist_ok=True)
    for t in tif_list:
        log.info("Clipping: %s", t)
        cmd = [
            'clip+na2zero',
            str(FS_BOUNDS),
            str(t),
            str(clipped_gridmetrics_dir / t.name),
        ]
        sp.run(cmd, check=True)

# Clip CHMs to Forest Service boundary and convert from VRTs to TIFFs
dep_counter += 1
chm1m_ft_clipped_tif_path = DST / f"{dep_counter:02d}_chm1m_ft_clipped_fs.tif"
chm05m_ft_clipped_tif_path = (
    DST / f"{dep_counter:02d}_chm05m_ft_clipped_fs.tif"
)
for src, dst, res in (
    (chm1m_ft_vrt_path, chm1m_ft_clipped_tif_path, "1"),
    (chm05m_ft_vrt_path, chm05m_ft_clipped_tif_path, "05"),
):
    if not dst.exists():
        log.info("Clip %sm CHM to FS and VRT to TIF...", res)
        clip_rast(src, dst, bounds=pyogrio.read_dataframe(FS_BOUNDS))
        gdaladdo(dst)

# Convert some grid-metric products from meters to feet
clipped_gridmetrics_ft_dir = (
    DST / f"{dep_counter:02d}_gridmetrics_mosaics_fs_clipped_ft"
)
if not clipped_gridmetrics_ft_dir.exists():
    log.info("Converting products from meters to feet...")
    clipped_gridmetrics_ft_dir.mkdir(exist_ok=True)
    src_paths = [
        *clipped_gridmetrics_dir.glob('gridmet20m_*_z_p*[0-9][0-9].tif'),
        *clipped_gridmetrics_dir.glob('gridmet20m_*_z_max.tif'),
        *clipped_gridmetrics_dir.glob('gridmet20m_*_z_mean.tif'),
        *clipped_gridmetrics_dir.glob('gridmet20m_*_z_min.tif'),
        *clipped_gridmetrics_dir.glob('gridmet20m_*_z_sd.tif'),
        *clipped_gridmetrics_dir.glob('gridmet20m_*_kde_peak*_diff.tif'),
        *clipped_gridmetrics_dir.glob('gridmet20m_*_kde_peak*_elev.tif'),
        *clipped_gridmetrics_dir.glob('gridmet20m_*_kde_peak*_value.tif'),
        *clipped_gridmetrics_dir.glob('gridmet20m_*_L[0-4].tif'),
    ]
    for src in src_paths:
        dst = f"{clipped_gridmetrics_ft_dir}/{src.stem}_ft.tif"
        log.info('%s  -->  %s', src.name, dst)
        tif_m2ft(src, dst)

# Group products into one directory
dep_counter += 1
final_product_dir = DST / f"{dep_counter:02d}_final_products"
if not final_product_dir.exists():
    log.info("Gathering products into one directory...")
    final_product_dir.mkdir(exist_ok=True)
    for p in (
        *clipped_gridmetrics_dir.glob("*.tif"),
        *clipped_gridmetrics_ft_dir.glob("*.tif"),
        chm1m_ft_clipped_tif_path,
        chm05m_ft_clipped_tif_path,
        patched_clipped_dtm_path,
    ):
        log.info("%s  -->  %s", p, final_product_dir / p.name)
        os.link(p, final_product_dir / p.name)

# Remove vertical component of CRS
    log.info("Correcting CRS info...")
    for p in final_product_dir.glob("*.tif"):
        log.info("Updating: %s", p)
        update_crs_metadata(p, FLAT_UTM13N_EPSG)

# Conform products to naming scheme
    log.info("Renaming and organizing raster products...")
    apply_naming_scheme(final_product_dir)

log.info("DONE")
